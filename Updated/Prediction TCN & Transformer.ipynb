{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c3624-a37e-4457-b8f6-e163521a13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using a Temporal Convolutional Network (TCN) to predict the movement of the stock price after the next 30 days i.e\n",
    "whether the stock price will close higher or not after 30 days from the present date price.\n",
    "\n",
    "The main reason to use TCN is its efficiency in capturing long-term dependencies and can process entire sequential data\n",
    "parallely. \n",
    "\n",
    "To overcome the overfitting, which is major problem in using TCN, L2 regularization, early stopping and dropout is used in the model.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dac273a-86be-4236-be41-a2881fe49046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the start date (YYYY-MM-DD):  2003-01-01\n",
      "Enter the end date (YYYY-MM-DD):  2024-05-31\n",
      "Enter the stock ticker:  ITC.NS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17356\\2534493523.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17356\\2534493523.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17356\\2534493523.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RSI'] = 100 - (100 / (1 + rs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - direction_output_accuracy: 0.5772 - loss: 4.8165 - strength_output_mse: 0.6135 - val_direction_output_accuracy: 0.6087 - val_loss: 3.8930 - val_strength_output_mse: 0.0478\n",
      "Epoch 2/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - direction_output_accuracy: 0.6068 - loss: 3.7827 - strength_output_mse: 0.0701 - val_direction_output_accuracy: 0.5990 - val_loss: 3.3423 - val_strength_output_mse: 0.0420\n",
      "Epoch 3/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - direction_output_accuracy: 0.6440 - loss: 3.1647 - strength_output_mse: 0.0307 - val_direction_output_accuracy: 0.6280 - val_loss: 2.7524 - val_strength_output_mse: 0.0275\n",
      "Epoch 4/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - direction_output_accuracy: 0.6431 - loss: 2.6164 - strength_output_mse: 0.0195 - val_direction_output_accuracy: 0.6280 - val_loss: 2.2578 - val_strength_output_mse: 0.0200\n",
      "Epoch 5/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - direction_output_accuracy: 0.6575 - loss: 2.1391 - strength_output_mse: 0.0143 - val_direction_output_accuracy: 0.6039 - val_loss: 1.8812 - val_strength_output_mse: 0.0272\n",
      "Epoch 6/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - direction_output_accuracy: 0.6759 - loss: 1.7564 - strength_output_mse: 0.0138 - val_direction_output_accuracy: 0.6643 - val_loss: 1.5225 - val_strength_output_mse: 0.0062\n",
      "Epoch 7/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - direction_output_accuracy: 0.6868 - loss: 1.4604 - strength_output_mse: 0.0119 - val_direction_output_accuracy: 0.6546 - val_loss: 1.3188 - val_strength_output_mse: 0.0200\n",
      "Epoch 8/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - direction_output_accuracy: 0.6875 - loss: 1.2373 - strength_output_mse: 0.0101 - val_direction_output_accuracy: 0.6763 - val_loss: 1.1253 - val_strength_output_mse: 0.0124\n",
      "Epoch 9/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - direction_output_accuracy: 0.7139 - loss: 1.0744 - strength_output_mse: 0.0116 - val_direction_output_accuracy: 0.6932 - val_loss: 0.9923 - val_strength_output_mse: 0.0176\n",
      "Epoch 10/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - direction_output_accuracy: 0.7014 - loss: 0.9590 - strength_output_mse: 0.0096 - val_direction_output_accuracy: 0.7077 - val_loss: 0.8896 - val_strength_output_mse: 0.0086\n",
      "Epoch 11/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - direction_output_accuracy: 0.7220 - loss: 0.8672 - strength_output_mse: 0.0081 - val_direction_output_accuracy: 0.7222 - val_loss: 0.8168 - val_strength_output_mse: 0.0092\n",
      "Epoch 12/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - direction_output_accuracy: 0.7376 - loss: 0.8071 - strength_output_mse: 0.0071 - val_direction_output_accuracy: 0.6353 - val_loss: 0.8743 - val_strength_output_mse: 0.0055\n",
      "Epoch 13/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - direction_output_accuracy: 0.7149 - loss: 0.7699 - strength_output_mse: 0.0068 - val_direction_output_accuracy: 0.7657 - val_loss: 0.7003 - val_strength_output_mse: 0.0052\n",
      "Epoch 14/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - direction_output_accuracy: 0.7435 - loss: 0.7094 - strength_output_mse: 0.0064 - val_direction_output_accuracy: 0.7222 - val_loss: 0.7370 - val_strength_output_mse: 0.0079\n",
      "Epoch 15/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - direction_output_accuracy: 0.7420 - loss: 0.7013 - strength_output_mse: 0.0075 - val_direction_output_accuracy: 0.6643 - val_loss: 0.7549 - val_strength_output_mse: 0.0140\n",
      "Epoch 16/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - direction_output_accuracy: 0.7405 - loss: 0.6744 - strength_output_mse: 0.0075 - val_direction_output_accuracy: 0.7246 - val_loss: 0.6857 - val_strength_output_mse: 0.0077\n",
      "Epoch 17/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - direction_output_accuracy: 0.7653 - loss: 0.6377 - strength_output_mse: 0.0063 - val_direction_output_accuracy: 0.7319 - val_loss: 0.6948 - val_strength_output_mse: 0.0080\n",
      "Epoch 18/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - direction_output_accuracy: 0.7684 - loss: 0.6543 - strength_output_mse: 0.0091 - val_direction_output_accuracy: 0.7319 - val_loss: 0.6254 - val_strength_output_mse: 0.0032\n",
      "Epoch 19/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - direction_output_accuracy: 0.7779 - loss: 0.6011 - strength_output_mse: 0.0051 - val_direction_output_accuracy: 0.6812 - val_loss: 0.7410 - val_strength_output_mse: 0.0226\n",
      "Epoch 20/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - direction_output_accuracy: 0.7735 - loss: 0.5927 - strength_output_mse: 0.0054 - val_direction_output_accuracy: 0.7705 - val_loss: 0.6037 - val_strength_output_mse: 0.0048\n",
      "Epoch 21/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - direction_output_accuracy: 0.7955 - loss: 0.5834 - strength_output_mse: 0.0059 - val_direction_output_accuracy: 0.7585 - val_loss: 0.6309 - val_strength_output_mse: 0.0047\n",
      "Epoch 22/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - direction_output_accuracy: 0.7733 - loss: 0.5908 - strength_output_mse: 0.0059 - val_direction_output_accuracy: 0.7802 - val_loss: 0.5992 - val_strength_output_mse: 0.0098\n",
      "Epoch 23/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - direction_output_accuracy: 0.7968 - loss: 0.5647 - strength_output_mse: 0.0051 - val_direction_output_accuracy: 0.7440 - val_loss: 0.6080 - val_strength_output_mse: 0.0031\n",
      "Epoch 24/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - direction_output_accuracy: 0.8065 - loss: 0.5559 - strength_output_mse: 0.0057 - val_direction_output_accuracy: 0.7488 - val_loss: 0.6447 - val_strength_output_mse: 0.0070\n",
      "Epoch 25/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - direction_output_accuracy: 0.8160 - loss: 0.5364 - strength_output_mse: 0.0055 - val_direction_output_accuracy: 0.7415 - val_loss: 0.6546 - val_strength_output_mse: 0.0220\n",
      "Epoch 26/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - direction_output_accuracy: 0.8105 - loss: 0.5392 - strength_output_mse: 0.0061 - val_direction_output_accuracy: 0.7705 - val_loss: 0.5879 - val_strength_output_mse: 0.0132\n",
      "Epoch 27/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - direction_output_accuracy: 0.8149 - loss: 0.5507 - strength_output_mse: 0.0050 - val_direction_output_accuracy: 0.7826 - val_loss: 0.5617 - val_strength_output_mse: 0.0089\n",
      "Epoch 28/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - direction_output_accuracy: 0.8140 - loss: 0.5483 - strength_output_mse: 0.0054 - val_direction_output_accuracy: 0.7367 - val_loss: 0.6490 - val_strength_output_mse: 0.0071\n",
      "Epoch 29/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - direction_output_accuracy: 0.8147 - loss: 0.5443 - strength_output_mse: 0.0047 - val_direction_output_accuracy: 0.7440 - val_loss: 0.6223 - val_strength_output_mse: 0.0037\n",
      "Epoch 30/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - direction_output_accuracy: 0.8213 - loss: 0.5412 - strength_output_mse: 0.0052 - val_direction_output_accuracy: 0.8188 - val_loss: 0.5434 - val_strength_output_mse: 0.0051\n",
      "Epoch 31/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - direction_output_accuracy: 0.8127 - loss: 0.5291 - strength_output_mse: 0.0050 - val_direction_output_accuracy: 0.7754 - val_loss: 0.5767 - val_strength_output_mse: 0.0056\n",
      "Epoch 32/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - direction_output_accuracy: 0.8283 - loss: 0.5174 - strength_output_mse: 0.0051 - val_direction_output_accuracy: 0.7995 - val_loss: 0.5556 - val_strength_output_mse: 0.0036\n",
      "Epoch 33/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - direction_output_accuracy: 0.8194 - loss: 0.5246 - strength_output_mse: 0.0053 - val_direction_output_accuracy: 0.8261 - val_loss: 0.5121 - val_strength_output_mse: 0.0089\n",
      "Epoch 34/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - direction_output_accuracy: 0.8234 - loss: 0.5077 - strength_output_mse: 0.0059 - val_direction_output_accuracy: 0.8164 - val_loss: 0.5340 - val_strength_output_mse: 0.0052\n",
      "Epoch 35/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - direction_output_accuracy: 0.8430 - loss: 0.5002 - strength_output_mse: 0.0055 - val_direction_output_accuracy: 0.8068 - val_loss: 0.5540 - val_strength_output_mse: 0.0106\n",
      "Epoch 36/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - direction_output_accuracy: 0.8250 - loss: 0.5181 - strength_output_mse: 0.0069 - val_direction_output_accuracy: 0.8068 - val_loss: 0.5573 - val_strength_output_mse: 0.0050\n",
      "Epoch 37/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - direction_output_accuracy: 0.8269 - loss: 0.5180 - strength_output_mse: 0.0066 - val_direction_output_accuracy: 0.8164 - val_loss: 0.5552 - val_strength_output_mse: 0.0117\n",
      "Epoch 38/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - direction_output_accuracy: 0.8354 - loss: 0.4960 - strength_output_mse: 0.0059 - val_direction_output_accuracy: 0.8454 - val_loss: 0.5126 - val_strength_output_mse: 0.0056\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - direction_output_accuracy: 0.7924 - loss: 0.5868 - strength_output_mse: 0.0090\n",
      "Test Loss: 0.5417\n",
      "Test Accuracy (Direction): 80.45%\n",
      "Test MSE (Strength): 0.0092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step\n",
      "Predicted Direction for Next 30 Days: Down\n",
      "Predicted Strength of Movement: 0.8457\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, BatchNormalization, Activation, Input, SpatialDropout1D, Add, Dropout\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Function to fetch stock data using yfinance\n",
    "def fetch_data(ticker, start_date, end_date):\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    stock_data.reset_index(inplace=True)  # Reset index to make 'Date' a column\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'])  # Convert 'Date' to datetime format\n",
    "    return stock_data[['Date', 'Close', 'Volume']]  # Return only the necessary columns\n",
    "\n",
    "# Get user input for date range and stock ticker\n",
    "start_date = input(\"Enter the start date (YYYY-MM-DD): \")\n",
    "end_date = input(\"Enter the end date (YYYY-MM-DD): \")\n",
    "ticker = input(\"Enter the stock ticker: \")\n",
    "\n",
    "# Fetch data for the given ticker and date range\n",
    "data = fetch_data(ticker, start_date, end_date)\n",
    "\n",
    "# Function to calculate technical indicators and add them to the DataFrame\n",
    "def add_technical_indicators(df):\n",
    "    # Simple Moving Averages (SMA)\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    \n",
    "    # Relative Strength Index (RSI)\n",
    "    delta = df['Close'].diff(1)\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Moving Average Convergence Divergence (MACD)\n",
    "    exp1 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = exp1 - exp2\n",
    "    df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['MACD_hist'] = df['MACD'] - df['MACD_signal']\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['BB_middle'] = df['Close'].rolling(window=20).mean()\n",
    "    df['BB_std'] = df['Close'].rolling(window=20).std()\n",
    "    df['BB_upper'] = df['BB_middle'] + (df['BB_std'] * 2)\n",
    "    df['BB_lower'] = df['BB_middle'] - (df['BB_std'] * 2)\n",
    "\n",
    "    # Rolling mean and standard deviation\n",
    "    df['Rolling_mean'] = df['Close'].rolling(window=20).mean()\n",
    "    df['Rolling_std'] = df['Close'].rolling(window=20).std()\n",
    "    \n",
    "    # Quarter of the year\n",
    "    df['Quarter'] = df['Date'].dt.quarter\n",
    "\n",
    "    df.dropna(inplace=True)  # Drop rows with NaN values\n",
    "    return df\n",
    "\n",
    "# Function to create lag features\n",
    "def add_lag_features(df, n_lags):\n",
    "    for lag in range(1, n_lags + 1):\n",
    "        df[f'Close_lag_{lag}'] = df['Close'].shift(lag)\n",
    "        df[f'Volume_lag_{lag}'] = df['Volume'].shift(lag)\n",
    "    df.dropna(inplace=True)  # Drop rows with NaN values after adding lag features\n",
    "    return df\n",
    "\n",
    "# Function to create sequences of data using sliding window approach\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys_direction, ys_strength = [], [], []\n",
    "    for i in range(len(data) - seq_length - 30):  # Adjust for 30-day prediction\n",
    "        x = data.iloc[i:(i + seq_length), 1:].values  # Close, Volume, and indicators\n",
    "        y_strength = data.iloc[i + seq_length + 30, 1]  # Closing price 30 days later\n",
    "        y_direction = (y_strength > data.iloc[i + seq_length - 1, 1]).astype(int)  # Direction: 1 if increase, else 0\n",
    "        xs.append(x)\n",
    "        ys_direction.append(y_direction)\n",
    "        ys_strength.append(y_strength)\n",
    "    return np.array(xs), np.array(ys_direction), np.array(ys_strength)\n",
    "\n",
    "# Add technical indicators and lag features to the data\n",
    "data = add_technical_indicators(data)\n",
    "data = add_lag_features(data, 5)  # Adding 5 lag features\n",
    "\n",
    "# Function to define a residual block for the TCN model\n",
    "def residual_block(x, filters, kernel_size, dilation_rate):\n",
    "    shortcut = Conv1D(filters, kernel_size=1, padding='causal')(x)  # Shortcut connection\n",
    "    x = Conv1D(filters, kernel_size, dilation_rate=dilation_rate, padding='causal', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Conv1D(filters, kernel_size, dilation_rate=dilation_rate, padding='causal', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([shortcut, x])  # Add shortcut connection\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Function to build the TCN model\n",
    "def build_tcn_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = residual_block(inputs, 64, 3, 1)  # First residual block\n",
    "    x = residual_block(x, 64, 3, 2)  # Second residual block\n",
    "    x = residual_block(x, 64, 3, 4)  # Third residual block\n",
    "    x = Flatten()(x)  # Flatten the output\n",
    "\n",
    "    direction_output = Dense(1, activation='sigmoid', name='direction_output')(x)  # Binary classification output\n",
    "    strength_output = Dense(1, name='strength_output')(x)  # Regression output\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[direction_output, strength_output])\n",
    "    model.compile(optimizer=Nadam(), loss=['binary_crossentropy', 'mse'], metrics={'direction_output': 'accuracy', 'strength_output': 'mse'})\n",
    "    return model\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "data.iloc[:, 1:] = scaler.fit_transform(data.iloc[:, 1:])\n",
    "\n",
    "# Sequence length for capturing patterns\n",
    "seq_length = 60\n",
    "X, y_direction, y_strength = create_sequences(data, seq_length)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_direction_train, y_direction_test, y_strength_train, y_strength_test = train_test_split(\n",
    "    X, y_direction, y_strength, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train the TCN model\n",
    "model = build_tcn_model((seq_length, X.shape[2]))\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model.fit(X_train, [y_direction_train, y_strength_train], epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(X_test, [y_direction_test, y_strength_test])\n",
    "print(f'Test Loss: {evaluation[0]:.4f}')\n",
    "print(f'Test Accuracy (Direction): {evaluation[1] * 100:.2f}%')\n",
    "print(f'Test MSE (Strength): {evaluation[2]:.4f}')\n",
    "\n",
    "# Predict for the next 30 days from end_date\n",
    "last_sequence = np.array(data.iloc[-seq_length:, 1:])  # Last 60 days\n",
    "last_sequence = last_sequence.reshape((1, seq_length, X.shape[2]))  # Reshape for TCN input\n",
    "predicted_direction, predicted_strength = model.predict(last_sequence)\n",
    "predicted_direction_class = (predicted_direction > 0.5).astype(int)\n",
    "print(f'Predicted Direction for Next 30 Days: {\"Up\" if predicted_direction_class[0][0] == 1 else \"Down\"}')\n",
    "print(f'Predicted Strength of Movement: {predicted_strength[0][0]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b72238-503e-48fc-996d-66630e6bd2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b57436-6c63-4579-ae4c-2353c9356fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The main idea for the below model is to predict the stock price movement after the next 30 days by leveraging correlation between two stocks.\n",
    "The best suited model to implement it is by using tranformer model.\n",
    "\n",
    "The model capture dependencies and correlations between different stocks at different time steps.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de649969-282d-474c-a944-35e2bde69e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the start date (YYYY-MM-DD):  2023-01-01\n",
      "Enter the end date (YYYY-MM-DD):  2024-05-31\n",
      "Enter the stock tickers (comma separated):  CANBK.NS, PNB.NS\n",
      "Enter the target stock ticker:  PNB.NS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17356\\1347202586.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['SMA_20'] = df['Close'].rolling(window=20).mean()  # 20-day simple moving average\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17356\\1347202586.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['SMA_50'] = df['Close'].rolling(window=50).mean()  # 50-day simple moving average\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17356\\1347202586.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['RSI'] = 100 - (100 / (1 + rs))  # Relative Strength Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - direction_output_accuracy: 0.8267 - loss: 13.8131 - strength_output_mse: 13.2097 - val_direction_output_accuracy: 0.7500 - val_loss: 1.1596 - val_strength_output_mse: 0.5514\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - direction_output_accuracy: 0.8477 - loss: 0.9084 - strength_output_mse: 0.4704 - val_direction_output_accuracy: 0.8125 - val_loss: 0.8730 - val_strength_output_mse: 0.3024\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - direction_output_accuracy: 0.8805 - loss: 0.7655 - strength_output_mse: 0.4144 - val_direction_output_accuracy: 0.8125 - val_loss: 0.8638 - val_strength_output_mse: 0.3793\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - direction_output_accuracy: 0.8547 - loss: 0.7558 - strength_output_mse: 0.3900 - val_direction_output_accuracy: 0.8125 - val_loss: 0.5829 - val_strength_output_mse: 0.1178\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - direction_output_accuracy: 0.8375 - loss: 0.7767 - strength_output_mse: 0.4698 - val_direction_output_accuracy: 0.8125 - val_loss: 0.6203 - val_strength_output_mse: 0.2013\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - direction_output_accuracy: 0.8879 - loss: 0.6100 - strength_output_mse: 0.3429 - val_direction_output_accuracy: 0.8125 - val_loss: 0.5523 - val_strength_output_mse: 0.1058\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - direction_output_accuracy: 0.9126 - loss: 0.5708 - strength_output_mse: 0.3423 - val_direction_output_accuracy: 0.8750 - val_loss: 0.4708 - val_strength_output_mse: 0.0825\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - direction_output_accuracy: 0.9217 - loss: 0.4942 - strength_output_mse: 0.2559 - val_direction_output_accuracy: 0.8125 - val_loss: 0.5733 - val_strength_output_mse: 0.1880\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - direction_output_accuracy: 0.9104 - loss: 0.5301 - strength_output_mse: 0.2966 - val_direction_output_accuracy: 0.8750 - val_loss: 0.4857 - val_strength_output_mse: 0.1141\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - direction_output_accuracy: 0.9530 - loss: 0.5511 - strength_output_mse: 0.3299 - val_direction_output_accuracy: 0.8125 - val_loss: 0.4411 - val_strength_output_mse: 0.0783\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - direction_output_accuracy: 0.9329 - loss: 0.4567 - strength_output_mse: 0.2565 - val_direction_output_accuracy: 0.8750 - val_loss: 0.4453 - val_strength_output_mse: 0.0945\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - direction_output_accuracy: 0.9352 - loss: 0.4855 - strength_output_mse: 0.2695 - val_direction_output_accuracy: 0.8750 - val_loss: 0.4351 - val_strength_output_mse: 0.0989\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - direction_output_accuracy: 0.9653 - loss: 0.4625 - strength_output_mse: 0.2794 - val_direction_output_accuracy: 0.8125 - val_loss: 0.4667 - val_strength_output_mse: 0.1081\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - direction_output_accuracy: 0.9112 - loss: 0.4582 - strength_output_mse: 0.2448 - val_direction_output_accuracy: 0.8750 - val_loss: 0.4481 - val_strength_output_mse: 0.0973\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - direction_output_accuracy: 0.9068 - loss: 0.4750 - strength_output_mse: 0.2744 - val_direction_output_accuracy: 0.8750 - val_loss: 0.5722 - val_strength_output_mse: 0.1853\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - direction_output_accuracy: 0.9602 - loss: 0.4086 - strength_output_mse: 0.2692 - val_direction_output_accuracy: 0.8750 - val_loss: 0.4225 - val_strength_output_mse: 0.0878\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - direction_output_accuracy: 0.9565 - loss: 0.3719 - strength_output_mse: 0.2259 - val_direction_output_accuracy: 0.8750 - val_loss: 0.4721 - val_strength_output_mse: 0.1418\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - direction_output_accuracy: 0.9669 - loss: 0.4148 - strength_output_mse: 0.2584 - val_direction_output_accuracy: 0.8125 - val_loss: 0.5170 - val_strength_output_mse: 0.1064\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - direction_output_accuracy: 0.9355 - loss: 0.3606 - strength_output_mse: 0.2047 - val_direction_output_accuracy: 0.8750 - val_loss: 0.4842 - val_strength_output_mse: 0.1305\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - direction_output_accuracy: 0.9635 - loss: 0.3265 - strength_output_mse: 0.1750 - val_direction_output_accuracy: 0.9375 - val_loss: 0.4305 - val_strength_output_mse: 0.0796\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - direction_output_accuracy: 0.9308 - loss: 0.3169 - strength_output_mse: 0.1567 - val_direction_output_accuracy: 0.8750 - val_loss: 0.3939 - val_strength_output_mse: 0.0826\n",
      "Epoch 22/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - direction_output_accuracy: 0.9719 - loss: 0.2885 - strength_output_mse: 0.1742 - val_direction_output_accuracy: 0.8750 - val_loss: 0.4873 - val_strength_output_mse: 0.0900\n",
      "Epoch 23/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - direction_output_accuracy: 0.9554 - loss: 0.3390 - strength_output_mse: 0.2064 - val_direction_output_accuracy: 0.8750 - val_loss: 0.4554 - val_strength_output_mse: 0.1076\n",
      "Epoch 24/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - direction_output_accuracy: 0.9579 - loss: 0.2842 - strength_output_mse: 0.1614 - val_direction_output_accuracy: 0.8750 - val_loss: 0.5510 - val_strength_output_mse: 0.1456\n",
      "Epoch 25/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - direction_output_accuracy: 0.9567 - loss: 0.2853 - strength_output_mse: 0.1592 - val_direction_output_accuracy: 0.8750 - val_loss: 0.4835 - val_strength_output_mse: 0.1214\n",
      "Epoch 26/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - direction_output_accuracy: 0.9682 - loss: 0.2771 - strength_output_mse: 0.1656 - val_direction_output_accuracy: 0.8750 - val_loss: 0.4651 - val_strength_output_mse: 0.1265\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - direction_output_accuracy: 0.7274 - loss: 0.5079 - strength_output_mse: 0.0651 \n",
      "Test Loss: 0.5080\n",
      "Test Accuracy (Direction): 73.17%\n",
      "Test MSE (Strength): 0.0681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "Predicted Direction for Next Month: Down\n",
      "Predicted Strength of Movement: 0.9688\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Fetch data using yfinance for the given tickers and date range\n",
    "def fetch_data(tickers, start_date, end_date):\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        stock_data.reset_index(inplace=True)  # Reset index to make 'Date' a column\n",
    "        stock_data['Date'] = pd.to_datetime(stock_data['Date'])  # Ensure 'Date' is in datetime format\n",
    "        data[ticker] = stock_data[['Date', 'Close', 'Volume']]  # Keep only relevant columns\n",
    "    return data\n",
    "\n",
    "# Add technical indicators to the dataframe\n",
    "def add_technical_indicators(df):\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()  # 20-day simple moving average\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()  # 50-day simple moving average\n",
    "    delta = df['Close'].diff(1)  # Difference between consecutive close prices\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()  # Average gains over 14 days\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()  # Average losses over 14 days\n",
    "    rs = gain / loss  # Relative Strength\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))  # Relative Strength Index\n",
    "    exp1 = df['Close'].ewm(span=12, adjust=False).mean()  # 12-day exponential moving average\n",
    "    exp2 = df['Close'].ewm(span=26, adjust=False).mean()  # 26-day exponential moving average\n",
    "    df['MACD'] = exp1 - exp2  # MACD\n",
    "    df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()  # MACD signal line\n",
    "    df['MACD_hist'] = df['MACD'] - df['MACD_signal']  # MACD histogram\n",
    "    df['BB_middle'] = df['Close'].rolling(window=20).mean()  # Bollinger Band middle line\n",
    "    df['BB_std'] = df['Close'].rolling(window=20).std()  # Bollinger Band standard deviation\n",
    "    df['BB_upper'] = df['BB_middle'] + (df['BB_std'] * 2)  # Bollinger Band upper line\n",
    "    df['BB_lower'] = df['BB_middle'] - (df['BB_std'] * 2)  # Bollinger Band lower line\n",
    "    df.dropna(inplace=True)  # Drop rows with NaN values\n",
    "    return df\n",
    "\n",
    "# Add lag features to the dataframe\n",
    "def add_lag_features(df, n_lags):\n",
    "    for lag in range(1, n_lags + 1):\n",
    "        df[f'Close_lag_{lag}'] = df['Close'].shift(lag)  # Lagged close price\n",
    "        df[f'Volume_lag_{lag}'] = df['Volume'].shift(lag)  # Lagged volume\n",
    "    df.dropna(inplace=True)  # Drop rows with NaN values\n",
    "    return df\n",
    "\n",
    "# Create sequences for the model to train on\n",
    "def create_sequences(data, seq_length, target_ticker):\n",
    "    if target_ticker not in data:\n",
    "        raise ValueError(f\"Target ticker {target_ticker} not found in the data.\")\n",
    "    \n",
    "    xs, ys_direction, ys_strength = [], [], []\n",
    "    for i in range(len(data[target_ticker]) - seq_length - 30):  # Adjust for 1-month prediction\n",
    "        x = []\n",
    "        for ticker in data:\n",
    "            x.append(data[ticker].iloc[i:(i + seq_length), 1:].values)  # Close, Volume, and indicators\n",
    "        x = np.concatenate(x, axis=1)  # Concatenate data from all tickers\n",
    "        y_strength = data[target_ticker].iloc[i + seq_length:i + seq_length + 30, 1].mean()  # Average close price of next month\n",
    "        y_direction = (y_strength > data[target_ticker].iloc[i + seq_length - 1, 1]).astype(int)  # Direction: 1 if increase, else 0\n",
    "        xs.append(x)\n",
    "        ys_direction.append(y_direction)\n",
    "        ys_strength.append(y_strength)\n",
    "    return np.array(xs), np.array(ys_direction), np.array(ys_strength)\n",
    "\n",
    "# Get user input for date range and target stock\n",
    "start_date = input(\"Enter the start date (YYYY-MM-DD): \")\n",
    "end_date = input(\"Enter the end date (YYYY-MM-DD): \")\n",
    "tickers = input(\"Enter the stock tickers (comma separated): \").split(',')\n",
    "target_ticker = input(\"Enter the target stock ticker: \")\n",
    "\n",
    "# Ensure the target ticker is included in the tickers list\n",
    "if target_ticker not in tickers:\n",
    "    tickers.append(target_ticker)\n",
    "\n",
    "# Fetch data\n",
    "data = fetch_data(tickers, start_date, end_date)\n",
    "\n",
    "# Add technical indicators and lag features to each stock's data\n",
    "for ticker in data:\n",
    "    data[ticker] = add_technical_indicators(data[ticker])\n",
    "    data[ticker] = add_lag_features(data[ticker], 5)  # Adding 5 lag features\n",
    "\n",
    "# Normalize the data\n",
    "scalers = {}\n",
    "for ticker in data:\n",
    "    scaler = MinMaxScaler()\n",
    "    data[ticker].iloc[:, 1:] = scaler.fit_transform(data[ticker].iloc[:, 1:])  # Normalize data except the Date column\n",
    "    scalers[ticker] = scaler\n",
    "\n",
    "# Sequence length for capturing patterns\n",
    "seq_length = 60\n",
    "X, y_direction, y_strength = create_sequences(data, seq_length, target_ticker)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_direction_train, y_direction_test, y_strength_train, y_strength_test = train_test_split(\n",
    "    X, y_direction, y_strength, test_size=0.2, random_state=42)  # 80% training, 20% testing\n",
    "\n",
    "# Build the Transformer model\n",
    "def build_transformer_model(input_shape, num_heads=4, ff_dim=64, dropout_rate=0.1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Self-Attention block\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=input_shape[-1])(x, x)  # Self-attention\n",
    "    attn_output = Dropout(dropout_rate)(attn_output)\n",
    "    x = attn_output + inputs  # Residual connection\n",
    "\n",
    "    # Feed-forward block\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    x_ff = Dense(ff_dim, activation='relu')(x)  # Feed-forward layer\n",
    "    x_ff = Dropout(dropout_rate)(x_ff)\n",
    "    x_ff = Dense(input_shape[-1])(x_ff)  # Output layer\n",
    "    x = x + x_ff  # Residual connection\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    direction_output = Dense(1, activation='sigmoid', name='direction_output')(x)  # Binary direction output\n",
    "    strength_output = Dense(1, name='strength_output')(x)  # Regression strength output\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[direction_output, strength_output])\n",
    "    model.compile(optimizer='nadam', loss=['binary_crossentropy', 'mse'], metrics={'direction_output': 'accuracy', 'strength_output': 'mse'})\n",
    "    return model\n",
    "\n",
    "# Define input shape and build the model\n",
    "input_shape = (seq_length, X.shape[2])\n",
    "transformer_model = build_transformer_model(input_shape)\n",
    "\n",
    "# Use early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "transformer_model.fit(X_train, [y_direction_train, y_strength_train], epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluation = transformer_model.evaluate(X_test, [y_direction_test, y_strength_test])\n",
    "print(f'Test Loss: {evaluation[0]:.4f}')\n",
    "print(f'Test Accuracy (Direction): {evaluation[1] * 100:.2f}%')\n",
    "print(f'Test MSE (Strength): {evaluation[2]:.4f}')\n",
    "\n",
    "# Predict for the next month for the target stock\n",
    "last_sequence = []\n",
    "for ticker in data:\n",
    "    last_sequence.append(data[ticker].iloc[-seq_length:, 1:].values)  # Get last 60 days of data\n",
    "last_sequence = np.concatenate(last_sequence, axis=1)\n",
    "last_sequence = last_sequence.reshape((1, seq_length, last_sequence.shape[1]))  # Reshape for Transformer input\n",
    "predicted_direction, predicted_strength = transformer_model.predict(last_sequence)\n",
    "predicted_direction_class = (predicted_direction > 0.5).astype(int)  # Convert to binary class\n",
    "print(f'Predicted Direction for Next Month: {\"Up\" if predicted_direction_class[0][0] == 1 else \"Down\"}')\n",
    "print(f'Predicted Strength of Movement: {predicted_strength[0][0]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe5f29d-e010-40c9-a3b6-6f50b450b020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a350b34-0f07-44de-b2de-6f54d5d62edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524bca3d-8fcc-4e45-9981-debb51aabebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58316898-561e-4083-8056-6ffd55976c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1f14b89-73b1-4813-9770-f89fc455b1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  100 of 100 completed\n",
      "             Stock1         Stock2  Correlation\n",
      "105   ADANIENSOL.NS        ATGL.NS     0.812693\n",
      "200     ADANIENT.NS  ADANIPORTS.NS     0.862945\n",
      "299   ADANIPORTS.NS    ADANIENT.NS     0.862945\n",
      "694         ATGL.NS  ADANIENSOL.NS     0.812693\n",
      "2149       CANBK.NS         PNB.NS     0.806034\n",
      "7050         PNB.NS       CANBK.NS     0.806034\n",
      "8300  TATAMOTORS.NS  TATAMTRDVR.NS     0.898641\n",
      "8399  TATAMTRDVR.NS  TATAMOTORS.NS     0.898641\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Load the CSV file containing Nifty50 stock tickers\n",
    "tickers_df = pd.read_csv('nifty50_tickers.csv')\n",
    "\n",
    "# Extract the tickers from the DataFrame\n",
    "tickers = tickers_df['Ticker'].tolist()\n",
    "\n",
    "# Download stock data using yfinance\n",
    "data = yf.download(tickers, start=\"2021-01-01\", end=\"2024-01-01\")['Adj Close']\n",
    "\n",
    "# Calculate daily returns\n",
    "returns = data.pct_change().dropna()\n",
    "\n",
    "# Create the correlation matrix\n",
    "correlation_matrix = returns.corr()\n",
    "\n",
    "# Flatten the correlation matrix and create a DataFrame\n",
    "correlation_data = correlation_matrix.stack().reset_index()\n",
    "correlation_data.columns = ['Stock1', 'Stock2', 'Correlation']\n",
    "correlation_data = correlation_data[correlation_data['Stock1'] != correlation_data['Stock2']]  # Remove self-correlation\n",
    "correlation_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Filter pairs with correlation >= 0.7\n",
    "high_correlation_pairs = correlation_data[correlation_data['Correlation'] >= 0.8]\n",
    "\n",
    "# Print the high correlation pairs\n",
    "print(high_correlation_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019ed96-fe10-4381-9357-6ea9356cbbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
